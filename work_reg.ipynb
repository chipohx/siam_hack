{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:12:42.311858Z",
     "start_time": "2025-03-03T17:12:42.295370Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import trapezoid\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import linregress"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:12:42.763955Z",
     "start_time": "2025-03-03T17:12:42.433210Z"
    }
   },
   "source": [
    "data_csv = pd.read_csv(\"hq_markup_train.csv\")\n",
    "bq_data_csv = pd.read_csv(\"markup_train.csv\")\n",
    "# data_csv"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:17:55.756935Z",
     "start_time": "2025-03-03T17:17:55.735421Z"
    }
   },
   "cell_type": "code",
   "source": "data_csv.isna().sum()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_name                                 0\n",
       "department_name                           0\n",
       "user_name                                 0\n",
       "Некачественное ГДИС                       0\n",
       "Влияние ствола скважины                   0\n",
       "Радиальный режим                          0\n",
       "Линейный режим                            0\n",
       "Билинейный режим                          0\n",
       "Сферический режим                         0\n",
       "Граница постоянного давления              0\n",
       "Граница непроницаемый разлом              0\n",
       "Влияние ствола скважины_details         143\n",
       "Радиальный режим_details                240\n",
       "Линейный режим_details                  398\n",
       "Билинейный режим_details                386\n",
       "Сферический режим_details               397\n",
       "Граница постоянного давления_details    402\n",
       "Граница непроницаемый разлом_details    398\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:13:01.558896Z",
     "start_time": "2025-03-03T17:13:01.538738Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from scipy.integrate import trapezoid\n",
    "\n",
    "def calculate_file_stats(data_csv: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Вычисляет статистические характеристики для каждого файла.\n",
    "\n",
    "    Параметры:\n",
    "    ----------\n",
    "    data_csv : pandas.DataFrame\n",
    "        DataFrame, содержащий столбец 'file_name' с именами файлов, которые нужно обработать.\n",
    "\n",
    "    Возвращает:\n",
    "    ----------\n",
    "    stats_by_file : pandas.DataFrame\n",
    "        DataFrame, содержащий статистические характеристики для каждого файла. Включает следующие столбцы:\n",
    "        - file_name: имя файла\n",
    "        - max_deltaP: максимальное значение deltaP\n",
    "        - min_deltaP: минимальное значение deltaP\n",
    "        - max_dP: максимальное значение dP\n",
    "        - min_dP: минимальное значение dP\n",
    "        - mean_deltaP: среднее значение deltaP\n",
    "        - mean_dP: среднее значение dP\n",
    "        - std_dP: стандартное отклонение dP\n",
    "        - peak_time: время пика dP\n",
    "        - slope_dP_before_peak: наклон dP до пика\n",
    "        - slope_dP_after_peak: наклон dP после пика\n",
    "        - integral_dP: интеграл dP по времени\n",
    "    \"\"\"\n",
    "    # пустой DataFrame для хранения статистики\n",
    "    stats_by_file = pd.DataFrame(columns=[\n",
    "        'file_name',\n",
    "        'max_deltaP',\n",
    "        'min_deltaP',\n",
    "        'max_dP',\n",
    "        'min_dP',\n",
    "        'mean_deltaP',\n",
    "        'mean_dP',\n",
    "        'std_dP',\n",
    "        'peak_time',\n",
    "        'slope_dP_before_peak',\n",
    "        'slope_dP_after_peak',\n",
    "        'integral_dP'\n",
    "    ])\n",
    "\n",
    "    for file_name in data_csv['file_name']:\n",
    "        \n",
    "        data = pd.read_csv(f'processed_data/{file_name}', delimiter='\\t', names=['t', 'deltaP', 'dP'])\n",
    "        \n",
    "        max_deltaP = data['deltaP'].max()\n",
    "        min_deltaP = data['deltaP'].min()\n",
    "        max_dP = data['dP'].max()\n",
    "        min_dP = data['dP'].min()\n",
    "        mean_deltaP = data['deltaP'].mean()\n",
    "        mean_dP = data['dP'].mean()\n",
    "        std_dP = data['dP'].std()\n",
    "\n",
    "        peak_idx = data[\"dP\"].idxmax()\n",
    "        peak_time = data.loc[peak_idx, 't']\n",
    "\n",
    "        slope_before, *_ = linregress(data['t'][:peak_idx+1], data[\"dP\"][:peak_idx+1])\n",
    "        slope_after, *_ = linregress(data['t'][peak_idx:], data[\"dP\"][peak_idx:])\n",
    "        slope_dP_before_peak = slope_before\n",
    "        slope_dP_after_peak = slope_after\n",
    "\n",
    "        integral_dP = trapezoid(data[\"dP\"], data['t'])\n",
    "\n",
    "        features_dict = {\n",
    "            'file_name': file_name,\n",
    "            'max_deltaP': max_deltaP,\n",
    "            'min_deltaP': min_deltaP,\n",
    "            'max_dP': max_dP,\n",
    "            'min_dP': min_dP,\n",
    "            'mean_deltaP': mean_deltaP,\n",
    "            'mean_dP': mean_dP,\n",
    "            'std_dP': std_dP,\n",
    "            'peak_time': peak_time,\n",
    "            'slope_dP_before_peak': slope_dP_before_peak,\n",
    "            'slope_dP_after_peak': slope_dP_after_peak,\n",
    "            'integral_dP': integral_dP\n",
    "        }\n",
    "\n",
    "        features_df = pd.DataFrame([features_dict])\n",
    "        stats_by_file = pd.concat([stats_by_file, features_df], ignore_index=True)\n",
    "\n",
    "    return stats_by_file"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Удалим все строки, которые указывают на пустой файл"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:13:06.911639Z",
     "start_time": "2025-03-03T17:13:03.673648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "indices_to_drop = []\n",
    "print(data_csv.shape)\n",
    "\n",
    "for index, file_name in enumerate(data_csv['file_name']):\n",
    "    txt_file = pd.read_csv(f'data/{file_name}', delimiter='\\t', names=['t', 'delta_p', 'dp'])\n",
    "    if len(txt_file) == 0:\n",
    "        indices_to_drop.append(index)\n",
    "\n",
    "data_csv = data_csv.drop(indices_to_drop).reset_index(drop=True)\n",
    "data_csv.shape"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:13:08.325770Z",
     "start_time": "2025-03-03T17:13:07.225555Z"
    }
   },
   "cell_type": "code",
   "source": "stats_by_file = calculate_file_stats(data_csv)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\Temp\\ipykernel_4748\\4035956134.py:60: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  peak_idx = data[\"dP\"].idxmax()\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m stats_by_file = \u001B[43mcalculate_file_stats\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_csv\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 61\u001B[39m, in \u001B[36mcalculate_file_stats\u001B[39m\u001B[34m(data_csv)\u001B[39m\n\u001B[32m     58\u001B[39m std_dP = data[\u001B[33m'\u001B[39m\u001B[33mdP\u001B[39m\u001B[33m'\u001B[39m].std()\n\u001B[32m     60\u001B[39m peak_idx = data[\u001B[33m\"\u001B[39m\u001B[33mdP\u001B[39m\u001B[33m\"\u001B[39m].idxmax()\n\u001B[32m---> \u001B[39m\u001B[32m61\u001B[39m peak_time = \u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpeak_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mt\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m     63\u001B[39m slope_before, *_ = linregress(data[\u001B[33m'\u001B[39m\u001B[33mt\u001B[39m\u001B[33m'\u001B[39m][:peak_idx+\u001B[32m1\u001B[39m], data[\u001B[33m\"\u001B[39m\u001B[33mdP\u001B[39m\u001B[33m\"\u001B[39m][:peak_idx+\u001B[32m1\u001B[39m])\n\u001B[32m     64\u001B[39m slope_after, *_ = linregress(data[\u001B[33m'\u001B[39m\u001B[33mt\u001B[39m\u001B[33m'\u001B[39m][peak_idx:], data[\u001B[33m\"\u001B[39m\u001B[33mdP\u001B[39m\u001B[33m\"\u001B[39m][peak_idx:])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1183\u001B[39m, in \u001B[36m_LocationIndexer.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   1181\u001B[39m     key = \u001B[38;5;28mtuple\u001B[39m(com.apply_if_callable(x, \u001B[38;5;28mself\u001B[39m.obj) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m key)\n\u001B[32m   1182\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._is_scalar_access(key):\n\u001B[32m-> \u001B[39m\u001B[32m1183\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtakeable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_takeable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1184\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_tuple(key)\n\u001B[32m   1185\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1186\u001B[39m     \u001B[38;5;66;03m# we by definition only have the 0th axis\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4221\u001B[39m, in \u001B[36mDataFrame._get_value\u001B[39m\u001B[34m(self, index, col, takeable)\u001B[39m\n\u001B[32m   4215\u001B[39m engine = \u001B[38;5;28mself\u001B[39m.index._engine\n\u001B[32m   4217\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.index, MultiIndex):\n\u001B[32m   4218\u001B[39m     \u001B[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001B[39;00m\n\u001B[32m   4219\u001B[39m     \u001B[38;5;66;03m#  results if our categories are integers that dont match our codes\u001B[39;00m\n\u001B[32m   4220\u001B[39m     \u001B[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4221\u001B[39m     row = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4222\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m series._values[row]\n\u001B[32m   4224\u001B[39m \u001B[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001B[39;00m\n\u001B[32m   4225\u001B[39m \u001B[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001B[39m, in \u001B[36mRangeIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m    415\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m    416\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Hashable):\n\u001B[32m--> \u001B[39m\u001B[32m417\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n\u001B[32m    418\u001B[39m \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n\u001B[32m    419\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[31mKeyError\u001B[39m: nan"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:12:48.871904700Z",
     "start_time": "2025-03-03T17:12:09.058102Z"
    }
   },
   "source": [
    "col_name = 'Билинейный режим_details'\n",
    "stats_by_file[col_name] = bq_data_csv[col_name]"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:12:48.871904700Z",
     "start_time": "2025-03-03T17:12:09.150430Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = stats_by_file.drop(columns=[col_name, 'file_name'])\n",
    "y = stats_by_file[col_name]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:12:48.872907700Z",
     "start_time": "2025-03-03T17:12:09.566543Z"
    }
   },
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=42, n_jobs=-1, max_depth=5)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'train: {root_mean_squared_error(y_train, model.predict(X_train))}')\n",
    "print(f'test: {root_mean_squared_error(y_test, model.predict(X_test))}')"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mensemble\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m RandomForestRegressor\n\u001B[32m      3\u001B[39m model = RandomForestRegressor(random_state=\u001B[32m42\u001B[39m, n_jobs=-\u001B[32m1\u001B[39m, max_depth=\u001B[32m5\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m y_pred = model.predict(X_test)\n\u001B[32m      9\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mtrain: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mroot_mean_squared_error(y_train,\u001B[38;5;250m \u001B[39mmodel.predict(X_train))\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:360\u001B[39m, in \u001B[36mBaseForest.fit\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m    357\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m issparse(y):\n\u001B[32m    358\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33msparse multilabel-indicator for y is not supported.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m360\u001B[39m X, y = \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    363\u001B[39m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    364\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    365\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcsc\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    366\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    367\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    368\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    369\u001B[39m \u001B[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001B[39;00m\n\u001B[32m    370\u001B[39m \u001B[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001B[39;00m\n\u001B[32m    371\u001B[39m \u001B[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001B[39;00m\n\u001B[32m    372\u001B[39m \u001B[38;5;66;03m# missing values.\u001B[39;00m\n\u001B[32m    373\u001B[39m estimator = \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m.estimator)(criterion=\u001B[38;5;28mself\u001B[39m.criterion)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001B[39m, in \u001B[36mvalidate_data\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2959\u001B[39m         y = check_array(y, input_name=\u001B[33m\"\u001B[39m\u001B[33my\u001B[39m\u001B[33m\"\u001B[39m, **check_y_params)\n\u001B[32m   2960\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2961\u001B[39m         X, y = \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2962\u001B[39m     out = X, y\n\u001B[32m   2964\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params.get(\u001B[33m\"\u001B[39m\u001B[33mensure_2d\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1387\u001B[39m, in \u001B[36mcheck_X_y\u001B[39m\u001B[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[39m\n\u001B[32m   1368\u001B[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001B[32m   1370\u001B[39m X = check_array(\n\u001B[32m   1371\u001B[39m     X,\n\u001B[32m   1372\u001B[39m     accept_sparse=accept_sparse,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1384\u001B[39m     input_name=\u001B[33m\"\u001B[39m\u001B[33mX\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   1385\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m1387\u001B[39m y = \u001B[43m_check_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_numeric\u001B[49m\u001B[43m=\u001B[49m\u001B[43my_numeric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1389\u001B[39m check_consistent_length(X, y)\n\u001B[32m   1391\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m X, y\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1397\u001B[39m, in \u001B[36m_check_y\u001B[39m\u001B[34m(y, multi_output, y_numeric, estimator)\u001B[39m\n\u001B[32m   1395\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001B[39;00m\n\u001B[32m   1396\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m multi_output:\n\u001B[32m-> \u001B[39m\u001B[32m1397\u001B[39m     y = \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1398\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1399\u001B[39m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcsr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1400\u001B[39m \u001B[43m        \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1401\u001B[39m \u001B[43m        \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1402\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1403\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43my\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1404\u001B[39m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1405\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1406\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1407\u001B[39m     estimator_name = _check_estimator_name(estimator)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001B[39m, in \u001B[36mcheck_array\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m   1101\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1102\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m expected <= 2.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1103\u001B[39m         % (array.ndim, estimator_name)\n\u001B[32m   1104\u001B[39m     )\n\u001B[32m   1106\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ensure_all_finite:\n\u001B[32m-> \u001B[39m\u001B[32m1107\u001B[39m     \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1108\u001B[39m \u001B[43m        \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1109\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1110\u001B[39m \u001B[43m        \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1111\u001B[39m \u001B[43m        \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mallow-nan\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1112\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1114\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[32m   1115\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_numpy_namespace(xp):\n\u001B[32m   1116\u001B[39m         \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001B[39m, in \u001B[36m_assert_all_finite\u001B[39m\u001B[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[32m    118\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m \u001B[43m_assert_all_finite_element_wise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    121\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[43m    \u001B[49m\u001B[43mxp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    123\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m=\u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    124\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    125\u001B[39m \u001B[43m    \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    126\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    127\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001B[39m, in \u001B[36m_assert_all_finite_element_wise\u001B[39m\u001B[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[39m\n\u001B[32m    152\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name == \u001B[33m\"\u001B[39m\u001B[33mX\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[32m    153\u001B[39m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[32m    154\u001B[39m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[32m    155\u001B[39m     msg_err += (\n\u001B[32m    156\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m does not accept missing values\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    157\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    167\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m#estimators-that-handle-nan-values\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    168\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m169\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[31mValueError\u001B[39m: Input y contains NaN."
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:12:48.872907700Z",
     "start_time": "2025-03-03T17:04:53.035176Z"
    }
   },
   "source": [
    "model.feature_importances_"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0651778 , 0.09518447, 0.04016259, 0.13434842, 0.06965723,\n",
       "       0.06267021, 0.08217348, 0.11508262, 0.13666945, 0.12559351,\n",
       "       0.07328023])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
