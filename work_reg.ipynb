{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T05:02:52.276752Z",
     "start_time": "2025-03-04T05:02:52.259420Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import trapezoid\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import linregress"
   ],
   "outputs": [],
   "execution_count": 161
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T05:02:52.629478Z",
     "start_time": "2025-03-04T05:02:52.345052Z"
    }
   },
   "source": [
    "data_csv = pd.read_csv(\"hq_markup_train.csv\")\n",
    "bq_data_csv = pd.read_csv(\"markup_train.csv\")\n",
    "# data_csv"
   ],
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Тут надо указать, какой файл и какой столбец будет обрабатываться "
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T05:02:52.713436Z",
     "start_time": "2025-03-04T05:02:52.707401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "work_file = data_csv\n",
    "bin_col_name = 'Билинейный режим'\n",
    "digit_col_name = 'Билинейный режим_details'"
   ],
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T05:02:52.800698Z",
     "start_time": "2025-03-04T05:02:52.795508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# col_name = 'Билинейный режим_details'\n",
    "# # col_name.replace('_details', '')\n",
    "# data_csv[data_csv[col_name.replace('_details', '')]==1][['Билинейный режим', 'Билинейный режим_details']].isna().sum()"
   ],
   "outputs": [],
   "execution_count": 164
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T05:02:52.915656Z",
     "start_time": "2025-03-04T05:02:52.900661Z"
    }
   },
   "source": [
    "def calculate_file_stats(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Вычисляет статистические характеристики для каждого файла.\n",
    "\n",
    "    Параметры:\n",
    "    ----------\n",
    "    dataframe : pandas.DataFrame\n",
    "        DataFrame, содержащий столбец 'file_name' с именами файлов, которые нужно обработать.\n",
    "\n",
    "    Возвращает:\n",
    "    ----------\n",
    "    stats_by_file : pandas.DataFrame\n",
    "        DataFrame, содержащий статистические характеристики для каждого файла. Включает следующие столбцы:\n",
    "        - file_name: имя файла\n",
    "        - max_deltaP: максимальное значение deltaP\n",
    "        - min_deltaP: минимальное значение deltaP\n",
    "        - max_dP: максимальное значение dP\n",
    "        - min_dP: минимальное значение dP\n",
    "        - mean_deltaP: среднее значение deltaP\n",
    "        - mean_dP: среднее значение dP\n",
    "        - std_dP: стандартное отклонение dP\n",
    "        - peak_time: время пика dP\n",
    "        - slope_dP_before_peak: наклон dP до пика\n",
    "        - slope_dP_after_peak: наклон dP после пика\n",
    "        - integral_dP: интеграл dP по времени\n",
    "    \"\"\"\n",
    "    # пустой DataFrame для хранения статистики\n",
    "    stats_by_file = pd.DataFrame(columns=[\n",
    "        'file_name',\n",
    "        'max_deltaP',\n",
    "        'min_deltaP',\n",
    "        'max_dP',\n",
    "        'min_dP',\n",
    "        'mean_deltaP',\n",
    "        'mean_dP',\n",
    "        'std_dP',\n",
    "        'peak_time',\n",
    "        'slope_dP_before_peak',\n",
    "        'slope_dP_after_peak',\n",
    "        'integral_dP'\n",
    "    ])\n",
    "\n",
    "    for file_name in dataframe['file_name']:\n",
    "        \n",
    "        data = pd.read_csv(f'data/{file_name}', delimiter='\\t', names=['t', 'deltaP', 'dP'])\n",
    "        \n",
    "        max_deltaP = data['deltaP'].max()\n",
    "        min_deltaP = data['deltaP'].min()\n",
    "        max_dP = data['dP'].max()\n",
    "        min_dP = data['dP'].min()\n",
    "        mean_deltaP = data['deltaP'].mean()\n",
    "        mean_dP = data['dP'].mean()\n",
    "        std_dP = data['dP'].std()\n",
    "\n",
    "        peak_idx = data[\"dP\"].idxmax()\n",
    "        peak_time = data.loc[peak_idx, 't']\n",
    "\n",
    "        slope_before, *_ = linregress(data['t'][:peak_idx+1], data[\"dP\"][:peak_idx+1])\n",
    "        slope_after, *_ = linregress(data['t'][peak_idx:], data[\"dP\"][peak_idx:])\n",
    "        slope_dP_before_peak = slope_before\n",
    "        slope_dP_after_peak = slope_after\n",
    "\n",
    "        integral_dP = trapezoid(data[\"dP\"], data['t'])\n",
    "\n",
    "        features_dict = {\n",
    "            'file_name': file_name,\n",
    "            'max_deltaP': max_deltaP,\n",
    "            'min_deltaP': min_deltaP,\n",
    "            'max_dP': max_dP,\n",
    "            'min_dP': min_dP,\n",
    "            'mean_deltaP': mean_deltaP,\n",
    "            'mean_dP': mean_dP,\n",
    "            'std_dP': std_dP,\n",
    "            'peak_time': peak_time,\n",
    "            'slope_dP_before_peak': slope_dP_before_peak,\n",
    "            'slope_dP_after_peak': slope_dP_after_peak,\n",
    "            'integral_dP': integral_dP\n",
    "        }\n",
    "\n",
    "        features_df = pd.DataFrame([features_dict])\n",
    "        stats_by_file = pd.concat([stats_by_file, features_df], ignore_index=True)\n",
    "\n",
    "    return stats_by_file"
   ],
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Удалим все строки, которые указывают на пустой файл"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T05:02:54.232472Z",
     "start_time": "2025-03-04T05:02:53.030081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "indices_to_drop = []\n",
    "print(work_file.shape)\n",
    "\n",
    "for index, file_name in enumerate(work_file['file_name']):\n",
    "    txt_file = pd.read_csv(f'data/{file_name}', delimiter='\\t', names=['t', 'delta_p', 'dp'])\n",
    "    if len(txt_file) == 0:\n",
    "        indices_to_drop.append(index)\n",
    "\n",
    "work_file = work_file.drop(indices_to_drop).reset_index(drop=True)\n",
    "work_file.shape"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 18)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T05:02:54.324551Z",
     "start_time": "2025-03-04T05:02:54.317128Z"
    }
   },
   "cell_type": "code",
   "source": "regression_data = work_file[work_file[bin_col_name]==1].reset_index(drop=True)",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stats_by_file = calculate_file_stats(regression_data)\n",
    "stats_by_file = stats_by_file.reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T05:02:55.112503Z",
     "start_time": "2025-03-04T05:02:55.107007Z"
    }
   },
   "source": [
    "# col_name = 'Билинейный режим_details'\n",
    "stats_by_file[digit_col_name] = regression_data[digit_col_name]"
   ],
   "outputs": [],
   "execution_count": 169
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T05:02:55.186004Z",
     "start_time": "2025-03-04T05:02:55.176864Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = stats_by_file.drop(columns=[digit_col_name, 'file_name'])\n",
    "y = stats_by_file[digit_col_name]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 170
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y.describe()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T05:02:55.399384Z",
     "start_time": "2025-03-04T05:02:55.392579Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T05:02:56.499150Z",
     "start_time": "2025-03-04T05:02:55.538625Z"
    }
   },
   "source": [
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=42, n_jobs=-1, max_depth=5)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'train rmse: {root_mean_squared_error(y_train, model.predict(X_train))}')\n",
    "print(f'test rmse: {root_mean_squared_error(y_test, model.predict(X_test))}')\n",
    "print(f'train mape: {mean_absolute_percentage_error(y_train, model.predict(X_train))}')\n",
    "print(f'test mape: {mean_absolute_percentage_error(y_test, model.predict(X_test))}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse: 0.16406662742195838\n",
      "test rmse: 0.2561705747070019\n",
      "train mape: 1.1382031968985804\n",
      "test mape: 1.3689997810080077\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T05:02:56.690178Z",
     "start_time": "2025-03-04T05:02:56.618703Z"
    }
   },
   "source": [
    "model.feature_importances_"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20101269, 0.05083238, 0.10935935, 0.1075651 , 0.09905236,\n",
       "       0.14935978, 0.09594139, 0.00440744, 0.01054387, 0.04356602,\n",
       "       0.12835962])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 173
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
