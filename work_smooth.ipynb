{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:02:49.380101Z",
     "start_time": "2025-03-03T17:02:49.364818Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import trapezoid\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import linregress"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:02:49.807968Z",
     "start_time": "2025-03-03T17:02:49.441822Z"
    }
   },
   "source": [
    "data_csv = pd.read_csv(\"hq_markup_train.csv\")\n",
    "bq_data_csv = pd.read_csv(\"markup_train.csv\")\n",
    "# data_csv"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:02:49.854033Z",
     "start_time": "2025-03-03T17:02:49.832302Z"
    }
   },
   "cell_type": "code",
   "source": "bq_data_csv.isna().sum()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_name                                   0\n",
       "department_name                             0\n",
       "user_name                                   0\n",
       "Некачественное ГДИС                         0\n",
       "Влияние ствола скважины                     0\n",
       "Радиальный режим                            0\n",
       "Линейный режим                              0\n",
       "Билинейный режим                            0\n",
       "Сферический режим                           0\n",
       "Граница постоянного давления                0\n",
       "Граница непроницаемый разлом                0\n",
       "Влияние ствола скважины_details          9583\n",
       "Радиальный режим_details                19286\n",
       "Линейный режим_details                  32930\n",
       "Билинейный режим_details                33055\n",
       "Сферический режим_details               39377\n",
       "Граница постоянного давления_details    40267\n",
       "Граница непроницаемый разлом_details    40876\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:02:50.003047Z",
     "start_time": "2025-03-03T17:02:49.983188Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from scipy.integrate import trapezoid\n",
    "\n",
    "def calculate_file_stats(data_csv: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Вычисляет статистические характеристики для каждого файла.\n",
    "\n",
    "    Параметры:\n",
    "    ----------\n",
    "    data_csv : pandas.DataFrame\n",
    "        DataFrame, содержащий столбец 'file_name' с именами файлов, которые нужно обработать.\n",
    "\n",
    "    Возвращает:\n",
    "    ----------\n",
    "    stats_by_file : pandas.DataFrame\n",
    "        DataFrame, содержащий статистические характеристики для каждого файла. Включает следующие столбцы:\n",
    "        - file_name: имя файла\n",
    "        - max_deltaP: максимальное значение deltaP\n",
    "        - min_deltaP: минимальное значение deltaP\n",
    "        - max_dP: максимальное значение dP\n",
    "        - min_dP: минимальное значение dP\n",
    "        - mean_deltaP: среднее значение deltaP\n",
    "        - mean_dP: среднее значение dP\n",
    "        - std_dP: стандартное отклонение dP\n",
    "        - peak_time: время пика dP\n",
    "        - slope_dP_before_peak: наклон dP до пика\n",
    "        - slope_dP_after_peak: наклон dP после пика\n",
    "        - integral_dP: интеграл dP по времени\n",
    "    \"\"\"\n",
    "    # пустой DataFrame для хранения статистики\n",
    "    stats_by_file = pd.DataFrame(columns=[\n",
    "        'file_name',\n",
    "        'max_deltaP',\n",
    "        'min_deltaP',\n",
    "        'max_dP',\n",
    "        'min_dP',\n",
    "        'mean_deltaP',\n",
    "        'mean_dP',\n",
    "        'std_dP',\n",
    "        'peak_time',\n",
    "        'slope_dP_before_peak',\n",
    "        'slope_dP_after_peak',\n",
    "        'integral_dP'\n",
    "    ])\n",
    "\n",
    "    for file_name in data_csv['file_name']:\n",
    "        \n",
    "        data = pd.read_csv(f'processed_data/{file_name}', delimiter='\\t', names=['t', 'deltaP', 'dP'])\n",
    "        \n",
    "        max_deltaP = data['deltaP'].max()\n",
    "        min_deltaP = data['deltaP'].min()\n",
    "        max_dP = data['dP'].max()\n",
    "        min_dP = data['dP'].min()\n",
    "        mean_deltaP = data['deltaP'].mean()\n",
    "        mean_dP = data['dP'].mean()\n",
    "        std_dP = data['dP'].std()\n",
    "\n",
    "        peak_idx = data[\"dP\"].idxmax()\n",
    "        peak_time = data.loc[peak_idx, 't']\n",
    "\n",
    "        slope_before, *_ = linregress(data['t'][:peak_idx+1], data[\"dP\"][:peak_idx+1])\n",
    "        slope_after, *_ = linregress(data['t'][peak_idx:], data[\"dP\"][peak_idx:])\n",
    "        slope_dP_before_peak = slope_before\n",
    "        slope_dP_after_peak = slope_after\n",
    "\n",
    "        integral_dP = trapezoid(data[\"dP\"], data['t'])\n",
    "\n",
    "        features_dict = {\n",
    "            'file_name': file_name,\n",
    "            'max_deltaP': max_deltaP,\n",
    "            'min_deltaP': min_deltaP,\n",
    "            'max_dP': max_dP,\n",
    "            'min_dP': min_dP,\n",
    "            'mean_deltaP': mean_deltaP,\n",
    "            'mean_dP': mean_dP,\n",
    "            'std_dP': std_dP,\n",
    "            'peak_time': peak_time,\n",
    "            'slope_dP_before_peak': slope_dP_before_peak,\n",
    "            'slope_dP_after_peak': slope_dP_after_peak,\n",
    "            'integral_dP': integral_dP\n",
    "        }\n",
    "\n",
    "        features_df = pd.DataFrame([features_dict])\n",
    "        stats_by_file = pd.concat([stats_by_file, features_df], ignore_index=True)\n",
    "\n",
    "    return stats_by_file"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Удалим все строки, которые указывают на пустой файл"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:02:52.555604Z",
     "start_time": "2025-03-03T17:02:50.618840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "indices_to_drop = []\n",
    "print(data_csv.shape)\n",
    "\n",
    "for index, file_name in enumerate(data_csv['file_name']):\n",
    "    txt_file = pd.read_csv(f'data/{file_name}', delimiter='\\t', names=['t', 'delta_p', 'dp'])\n",
    "    if len(txt_file) == 0:\n",
    "        indices_to_drop.append(index)\n",
    "\n",
    "data_csv = data_csv.drop(indices_to_drop).reset_index(drop=True)\n",
    "data_csv.shape"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 18)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:02:52.963669Z",
     "start_time": "2025-03-03T17:02:52.653563Z"
    }
   },
   "cell_type": "code",
   "source": "stats_by_file = calculate_file_stats(data_csv)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\Temp\\ipykernel_3776\\4035956134.py:60: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  peak_idx = data[\"dP\"].idxmax()\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m stats_by_file = \u001B[43mcalculate_file_stats\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_csv\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 61\u001B[39m, in \u001B[36mcalculate_file_stats\u001B[39m\u001B[34m(data_csv)\u001B[39m\n\u001B[32m     58\u001B[39m std_dP = data[\u001B[33m'\u001B[39m\u001B[33mdP\u001B[39m\u001B[33m'\u001B[39m].std()\n\u001B[32m     60\u001B[39m peak_idx = data[\u001B[33m\"\u001B[39m\u001B[33mdP\u001B[39m\u001B[33m\"\u001B[39m].idxmax()\n\u001B[32m---> \u001B[39m\u001B[32m61\u001B[39m peak_time = \u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpeak_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mt\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m     63\u001B[39m slope_before, *_ = linregress(data[\u001B[33m'\u001B[39m\u001B[33mt\u001B[39m\u001B[33m'\u001B[39m][:peak_idx+\u001B[32m1\u001B[39m], data[\u001B[33m\"\u001B[39m\u001B[33mdP\u001B[39m\u001B[33m\"\u001B[39m][:peak_idx+\u001B[32m1\u001B[39m])\n\u001B[32m     64\u001B[39m slope_after, *_ = linregress(data[\u001B[33m'\u001B[39m\u001B[33mt\u001B[39m\u001B[33m'\u001B[39m][peak_idx:], data[\u001B[33m\"\u001B[39m\u001B[33mdP\u001B[39m\u001B[33m\"\u001B[39m][peak_idx:])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1183\u001B[39m, in \u001B[36m_LocationIndexer.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   1181\u001B[39m     key = \u001B[38;5;28mtuple\u001B[39m(com.apply_if_callable(x, \u001B[38;5;28mself\u001B[39m.obj) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m key)\n\u001B[32m   1182\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._is_scalar_access(key):\n\u001B[32m-> \u001B[39m\u001B[32m1183\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtakeable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_takeable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1184\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_tuple(key)\n\u001B[32m   1185\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1186\u001B[39m     \u001B[38;5;66;03m# we by definition only have the 0th axis\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4221\u001B[39m, in \u001B[36mDataFrame._get_value\u001B[39m\u001B[34m(self, index, col, takeable)\u001B[39m\n\u001B[32m   4215\u001B[39m engine = \u001B[38;5;28mself\u001B[39m.index._engine\n\u001B[32m   4217\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.index, MultiIndex):\n\u001B[32m   4218\u001B[39m     \u001B[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001B[39;00m\n\u001B[32m   4219\u001B[39m     \u001B[38;5;66;03m#  results if our categories are integers that dont match our codes\u001B[39;00m\n\u001B[32m   4220\u001B[39m     \u001B[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4221\u001B[39m     row = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4222\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m series._values[row]\n\u001B[32m   4224\u001B[39m \u001B[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001B[39;00m\n\u001B[32m   4225\u001B[39m \u001B[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\siam_data\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001B[39m, in \u001B[36mRangeIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m    415\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m    416\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Hashable):\n\u001B[32m--> \u001B[39m\u001B[32m417\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n\u001B[32m    418\u001B[39m \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n\u001B[32m    419\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[31mKeyError\u001B[39m: nan"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:02:53.100625300Z",
     "start_time": "2025-03-03T16:57:36.801375Z"
    }
   },
   "source": [
    "col_name = 'Билинейный режим'\n",
    "stats_by_file[col_name] = data_csv[col_name]"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:02:53.101624300Z",
     "start_time": "2025-03-03T16:57:36.954892Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = stats_by_file.drop(columns=[col_name, 'file_name'])\n",
    "y = stats_by_file[col_name]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:02:53.101624300Z",
     "start_time": "2025-03-03T16:57:36.978760Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1, max_depth=5, class_weight='balanced')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'train: {accuracy_score(y_train, model.predict(X_train))}')\n",
    "print(f'test: {accuracy_score(y_test, model.predict(X_test))}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.8625\n",
      "test: 0.82\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:02:53.101624300Z",
     "start_time": "2025-03-03T16:57:37.559191Z"
    }
   },
   "source": [
    "model.feature_importances_"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06230691, 0.0644637 , 0.05078044, 0.098182  , 0.06132472,\n",
       "       0.05942083, 0.0562122 , 0.18946001, 0.11664145, 0.06269865,\n",
       "       0.17850909])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
